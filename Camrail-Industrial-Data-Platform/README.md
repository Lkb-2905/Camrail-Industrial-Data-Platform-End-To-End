ğŸŒ DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
# âš¡ CIDP : Camrail Industrial Data Platform
![Terraform](https://img.shields.io/badge/Terraform-Infrastructure_As_Code-purple) ![Azure_DevOps](https://img.shields.io/badge/Azure_Pipelines-CI/CD-blue) ![Kubernetes](https://img.shields.io/badge/Kubernetes-AKS_Cluster-blue) ![Grafana](https://img.shields.io/badge/Grafana-SRE_Dashboards-orange)

**Version:** 3.0.0 Enterprise | **Date:** FÃ©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr  

ğŸš€ [DÃ©marrage Rapide](#-dÃ©marrage-rapide) â€¢ ğŸ“š [Documentation](#-guide-dutilisation) â€¢ ğŸ¯ [FonctionnalitÃ©s](#-fonctionnalitÃ©s-clÃ©s) â€¢ ğŸ”§ [Installation](#-installation-rapide)

---

## ğŸ“‹ TABLE DES MATIÃˆRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique](#ï¸-architecture-technique)
3. [Stack Technologique](#ï¸-stack-technologique)
4. [FonctionnalitÃ©s ClÃ©s](#-fonctionnalitÃ©s-clÃ©s)
5. [DÃ©marrage Rapide](#-dÃ©marrage-rapide)
6. [Guide d'Utilisation](#-guide-dutilisation)
7. [QualitÃ© & Best Practices](#-qualitÃ©--best-practices)
8. [Roadmap & Ã‰volutions](#ï¸-roadmap--Ã©volutions)

---

## ğŸ¯ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
L'**Industrial Data Platform (End-to-End)** dÃ©montre de magistrales capacitÃ©s d'architecture orientÃ©e *Data-Driven* globale. Ce projet hybride rÃ©unit l'IngÃ©nierie de la DonnÃ©e (ETL SQL) et la Data Science (Moteurs ML connectÃ©s Base de DonnÃ©es) dans une usine logicielle ferroviaire critique de grande ampleur.

Il illustre de A Ã  Z les compÃ©tences absolues suivantes :

âœ… **Architecture E2E Hexagonale :** Isolation de l'ETL (Extrait Moteur) et de la ML Data Science.
âœ… **Azure DevOps CI/CD :** Pipeline automatisÃ© des tests jusqu'au dÃ©ploiement (AKS).
âœ… **Infrastructure as Code (Terraform) :** Provisionnement complet et auditable de l'architecture Microsoft Azure.
âœ… **Kubernetes (AKS) :** Conteneurisation et auto-scaling horizontal de l'IA (API ML + Workers Kafka).
âœ… **ObservabilitÃ© Grafana / Prometheus :** Dashboards complets d'analyse des anomalies mÃ©tiers (SRE).
âœ… **Streaming IoT Temps RÃ©el (Kafka) :** Ingestion continue et asynchrone des flux capteurs massifs.
âœ… **Data Warehouse Cloud (PostgreSQL) :** Stockage relationnel lourd, robuste avec des capacitÃ©s gÃ©ospatiales.
âœ… **Mode Local (Bootstrap) :** ExÃ©cution autonome sans PostgreSQL/Kafka via `bootstrap_local.py` et API Flask.

### Pourquoi ce projet ?
| Aspect | DÃ©monstration |
| --- | --- |
| **ScalabilitÃ©** | L'Auto-Scaler Kubernetes multiplie les conteneurs API selon la charge Kafka. |
| **MaintenabilitÃ©** | L'Infrastructure `main.tf` permet un redÃ©ploiement complet en < 10min. |
| **Innovation** | Le CI/CD Azure Pipelines garantit 0 bug en production lors des upgrades IA. |
| **SÃ©curitÃ©** | Gestion Cloud Azure sÃ©curisant les connexions Pods / Database via Secrets K8s. API sÃ©curisÃ©e par `X-API-KEY` transmise dans le Dashboard Streamlit. |
| **Performance** | Monitoring visuel temps rÃ©el via Dashboards Grafana couplÃ©s Ã  Prometheus. |

---

## ğŸ—ï¸ ARCHITECTURE TECHNIQUE

### Diagramme de Flux (Vue Logique & Local)
```mermaid
flowchart TD
    classDef client fill:#38bdf8,stroke:#0284c7,stroke-width:2px,color:#000
    classDef app fill:#4ade80,stroke:#16a34a,stroke-width:2px,color:#000
    classDef intel fill:#facc15,stroke:#ca8a04,stroke-width:2px,color:#000
    classDef data fill:#f87171,stroke:#dc2626,stroke-width:2px,color:#fff
    classDef darkBox fill:#27272a,stroke:#52525b,stroke-width:2px,color:#fff

    subgraph Client_Layer["Client Layer"]
        O[ğŸ‘¤ OpÃ©rateur Logistique]:::darkBox -->|Pilotage| R[Streamlit Dashboard<br>Port 8501]:::client
    end

    subgraph Application_Layer["Application Layer"]
        N[Flask API Backend<br>Port 5000]:::app
        S[Service MÃ©tier]:::darkBox
        R -->|HTTP GET/POST| N
        N -->|API Request| SL
        N -->|Fallback| OM
        N -->|Orchestration| S
    end

    subgraph Data_Sources["Data Sources"]
        OM[Kafka / PostgreSQL<br>DonnÃ©es RÃ©elles]:::data
        SL[Simulateur Local<br>DonnÃ©es SynthÃ©tiques]:::data
        SL -.-> OM
    end

    subgraph Intelligence_Layer["Intelligence Layer"]
        P[Python Engine<br>Scikit-Learn]:::intel
    end

    S -->|Shell Execution| P
    P -->|JSON Output| S

    style Client_Layer fill:#3f3f46,stroke:#52525b,color:#fff
    style Application_Layer fill:#3f3f46,stroke:#52525b,color:#fff
    style Data_Sources fill:#3f3f46,stroke:#52525b,color:#fff
    style Intelligence_Layer fill:#3f3f46,stroke:#52525b,color:#fff
```

**RÃ©sultat visuel â€” Dashboard en action :**

Les trois captures ci-dessous s'affichent directement dans le README.

**1. Vue gÃ©nÃ©rale** â€” OPÃ‰RATION NOMINALE (valeurs nominales) :

![Dashboard Streamlit â€” Vue gÃ©nÃ©rale](../docs/screenshots/01_cidp_dashboard_vue_generale.png)

**2. Cas alerte** â€” DANGER DÃ‰TECTÃ‰ (banniÃ¨re rouge, Vibrations/TempÃ©rature Ã©levÃ©es) :

![Dashboard Streamlit â€” Cas alerte](../docs/screenshots/02_cidp_dashboard_alerte_danger.png)

**3. DÃ©pannage** â€” Erreur ReadTimeout si l'API Flask n'est pas dÃ©marrÃ©e sur le port 5000 :

![Dashboard â€” Erreur ReadTimeout](../docs/screenshots/09_cidp_dashboard_error_timeout.png)

### Architecture Infra (Cloud)

Vue dâ€™ensemble du dÃ©ploiement sur Microsoft Azure (AKS, PostgreSQL, CI/CD).

#### Diagramme de flux

```mermaid
flowchart LR
    subgraph Client
        U[ğŸ‘¤ OpÃ©rateur]
        P[BI Dashboard]
        U --> P
    end

    subgraph CICD["Azure DevOps CI/CD"]
        AZ[Build Â· Test Â· Push]
    end

    subgraph AKS["Azure Kubernetes Service"]
        K[Kafka]
        O[Consumer ETL]
        M[API Flask ML]
        PR[Prometheus]
        GF[Grafana]
        K --> O
        M --> PR --> GF
    end

    subgraph Infra
        TF[Terraform]
    end

    subgraph Data
        S[Capteurs IoT]
        D[(PostgreSQL)]
    end

    S --> K
    O --> D
    D --> M
    M --> P
    AZ --> TF
    TF --> AKS
```

### Flux de DonnÃ©es DÃ©taillÃ©
1. **Infrastructure as Code** : Terraform instancie l'Event Hub, Azure Postgres et le Cluster Kubernetes de 0.
2. **DÃ©ploiement CI/CD** : Toute modification Master dÃ©clenche Azure DevOps qui compile l'image Docker, exÃ©cute `Pytest` et dÃ©ploie le YAML sur AKS.
3. **Architecture DistribuÃ©e (K8s)** : Les pods ETL capturent les Ã©vÃ¨nements Kafka et l'A.I API lit depuis la base Azure.
4. **Mode Local (Bootstrap)** : En absence de PostgreSQL/Kafka, `bootstrap_local.py` entraÃ®ne le modÃ¨le depuis les CSV (`data/sensors.csv`, `data/maintenance.csv`) et gÃ©nÃ¨re `models/latest.pkl`, permettant Ã  l'API et au Dashboard Streamlit de fonctionner en autonomie.
5. **Monitoring Ops (Grafana)** : Prometheus scrape les mÃ©triques (`/metrics`) du conteneur ML, que Grafana expose sous forme de Dashboard exÃ©cutif temps rÃ©el.
6. **Diffusion Live** : Dashboard Streamlit (port 8501) appelle l'API (port 5000) avec authentification `X-API-KEY` pour afficher les prÃ©dictions en temps rÃ©el.

---

## ğŸ› ï¸ STACK TECHNOLOGIQUE

### Technologies Core
| Composant | Technologie | Version | Justification Technique |
| --- | --- | --- | --- |
| **Infrastructure Cloud** | Terraform / Azure | Latest | DÃ©ploiement automatisÃ© (IaC) de l'usine logicielle complÃ¨te sur le Cloud Microsoft Azure. |
| **SGBD Cloud** | PostgreSQL | 15+ | Data Warehouse Enterprise-Grade pour stockage massif relationnel et analytique. |
| **Intelligence Artificielle**| Scikit-Learn | Latest | Algorithmes Random Forest industriels pour la maintenance prÃ©dictive. |
| **Orchestration & DevOps**| Kubernetes (AKS) | Latest | Auto-scaling des Pods API et des Workers Kafka via CI/CD Azure Pipelines. |
| **Dashboard Interactif** | Streamlit | Latest | Interface de dÃ©mo temps rÃ©el avec sliders (DÃ©bit, Pression, Vibration, TempÃ©rature) et appel API sÃ©curisÃ©. |

### BibliothÃ¨ques ComplÃ©mentaires
* **Loguru :** Remplacement intelligent du standard logger pour une traccabilitÃ© magistrale.
* **Pyenv :** Verrouillage strict de l'environnement Python utilisÃ©.
* **Pydantic :** Validation des payloads API et compatibilitÃ© v1/v2 (`.dict()` / `.model_dump()`).

---

## ğŸ¯ FONCTIONNALITÃ‰S CLÃ‰S

### ğŸš€ FonctionnalitÃ©s Principales
**Usine NumÃ©rique Cloud Native**
* DÃ©ploiement asynchrone orchestrÃ© par Terraform sur Azure Kubernetes Service. Supervision E2E Grafana.

**Algorithmes de Machine Learning sur PostgreSQL**
* Calcul des scores de risques vitaux enregistrÃ©s directement dans la base de donnÃ©es distante.

**Mode Local (Bootstrap)**
* Script `bootstrap_local.py` : entraÃ®nement du modÃ¨le depuis les CSV locaux â†’ `models/latest.pkl`. Permet une dÃ©mo complÃ¨te sans infrastructure Cloud.

**Dashboard Streamlit**
* Interface "Camrail Live Monitor" (localhost:8501) avec outil de test manuel : sliders pour simuler la tÃ©lÃ©mÃ©trie, bouton "Interroger l'API Neural Network", affichage "OPÃ‰RATION NOMINALE" ou "DANGER DÃ‰TECTÃ‰" selon les prÃ©dictions.

**MÃ©canismes SRE (Site Reliability Engineering)**
* Alerting Prometheus actif bloquant l'API si le modÃ¨le de Machine Learning diverge ou tombe en latence.

### ğŸ›¡ï¸ SÃ©curitÃ© & Robustesse
| Aspect | ImplÃ©mentation |
| --- | --- |
| **RÃ©silience Kubernetes** | Le Load Balancer Kubernetes reroute le flux en millisecondes si un Worker s'arrÃªte. |
| **SÃ©curitÃ© d'API** | Schema Validation via Pydantic et X-API-KEY intÃ©grÃ©e dans les Pods IA. Le Dashboard Streamlit transmet automatiquement le header `X-API-KEY` Ã  l'API Flask. |
| **TraÃ§abilitÃ© SRE** | Dashboard complet Grafana monitorant la santÃ© de chaque micro-service. |
| **Timeout & Erreurs** | Timeout API 15s, messages d'erreur explicites (API injoignable, ReadTimeout). |

---

## ğŸš€ DÃ‰MARRAGE RAPIDE

### PrÃ©requis
* Docker Desktop & Kubernetes (mode Cloud)
* Terraform Azure CLI (`az`) (mode Cloud)
* Python (v3.12+ pour le mode local)

### DÃ©ploiement Architecte (Cloud Microsoft Azure)
```bash
# 1. Provisionner l'infrastructure Cloud complÃ¨te
cd terraform
terraform init && terraform apply -auto-approve

# 2. Le CI/CD Azure DevOps compile et dÃ©ploie les Pods ML 
# sur AKS automatiquement au moindre push GitHub.
```

### Lancement DÃ©veloppeur (Mode Local â€” RecommandÃ© pour dÃ©mo)

> ğŸ’¡ Utilisez le Python de **pyenv** si `python` ou `pip` ne sont pas configurÃ©s correctement.

```powershell
# 1. Installer les dÃ©pendances (pyenv recommandÃ©)
cd "c:\Users\pc\Desktop\projet CAMRAIL\Camrail-Industrial-Data-Platform"
& "$env:USERPROFILE\.pyenv\pyenv-win\versions\3.12.10\python.exe" -m pip install -r requirements.txt

# 2. Bootstrap du modÃ¨le puis API â€” Terminal 1
$env:PYTHONPATH = (Get-Location).Path
& "$env:USERPROFILE\.pyenv\pyenv-win\versions\3.12.10\python.exe" bootstrap_local.py
& "$env:USERPROFILE\.pyenv\pyenv-win\versions\3.12.10\python.exe" api/api.py

# 3. Dashboard Streamlit â€” Terminal 2 (dans le mÃªme dossier)
cd "c:\Users\pc\Desktop\projet CAMRAIL\Camrail-Industrial-Data-Platform"
& "$env:USERPROFILE\.pyenv\pyenv-win\versions\3.12.10\python.exe" -m streamlit run dashboard/app.py
```

**Ordre requis :** Bootstrap + API en premier ; le Dashboard interroge l'API sur le port 5000 (sinon ReadTimeout).

**AccÃ¨s ImmÃ©diat :**
* API : **http://127.0.0.1:5000** (GET `/health`, POST `/predict` avec header `X-API-KEY: entreprise_secret_key_2026`)
* Dashboard : **http://localhost:8501** â€” Camrail Live Monitor (la clÃ© API est transmise automatiquement par le Dashboard)

### Lancement Mode Complet (PostgreSQL + Kafka)
```bash
python run_platform.py
```

---

## ğŸ“– GUIDE D'UTILISATION

### ScÃ©nario de Pilotage
1. **Lancement Kafka & Microservices :** Laissez les Deployments Kubernetes assurer l'ingestion asynchrone IoT.
2. **Supervision BI ConnectÃ©e :** En utilisant le connecteur DirectQuery PostgreSQL, connectez vos outils Power BI/Grafana pour surveiller la santÃ© des locomotives Ã  la seconde prÃ¨s.
3. **DÃ©mo Recruteur :** Lancer l'API + Dashboard, afficher le cas nominal (Vibration 2, TempÃ©rature 45), puis simuler une alerte (Vibration 7+, TempÃ©rature 85+) et montrer le message "DANGER DÃ‰TECTÃ‰".

### Captures d'Ã‰cran

Chaque capture est affichÃ©e ci-dessous avec sa lÃ©gende.

**01 â€” Vue gÃ©nÃ©rale** â€” Dashboard nominal (OPÃ‰RATION NOMINALE) :

![Dashboard CIDP â€” Vue gÃ©nÃ©rale](../docs/screenshots/01_cidp_dashboard_vue_generale.png)

---

**02 â€” Cas alerte** â€” DANGER DÃ‰TECTÃ‰ (banniÃ¨re rouge) :

![Dashboard CIDP â€” Cas alerte](../docs/screenshots/02_cidp_dashboard_alerte_danger.png)

---

**04 â€” Bootstrap + API** â€” Terminal : dÃ©marrage de `bootstrap_local.py` et API Flask :

![Bootstrap et dÃ©marrage API Flask](../docs/screenshots/04_cidp_bootstrap_api_demarrage.png)

---

**09 â€” DÃ©pannage** â€” Erreur ReadTimeout si l'API n'est pas dÃ©marrÃ©e sur le port 5000 :

![Erreur ReadTimeout â€” API non dÃ©marrÃ©e](../docs/screenshots/09_cidp_dashboard_error_timeout.png)

> ğŸ’¡ Captures dans `docs/screenshots/` â€” Convention : voir `../docs/screenshots/README.md`

---

## âœ¨ QUALITÃ‰ & BEST PRACTICES

### Standards de Code
* **ModularitÃ© (Hexagonale) :** Couches rÃ©parties avec rigueur.
* **Clean Code Data :** L'intelligence ne pervertit pas les couches basses, la connexion est une API via SGBD.
* **Error Handling :** Exception Management `try-except sys.exit(1)` garantissant la puretÃ© du pipeline.
* **CompatibilitÃ© Pydantic :** Gestion transparente Pydantic v1 et v2 pour les payloads API.

### MÃ©triques d'Excellence
âœ… **Couverture fonctionnelle :** L'ExtrÃªme bout-en-bout d'une compÃ©tence d'IngÃ©nieur Full-Stack Data en action.
âœ… **Performance globale :** Architecture `Zero-Downtime` SQL SupportÃ©e.
âœ… **Tests automatisÃ©s :** `pytest tests/test_api.py` â€” 4 tests (health, unauthorized, schema validation, bad method).

---

## ğŸ—ºï¸ ROADMAP & Ã‰VOLUTIONS

**Version Actuelle : 3.0.0 (Enterprise V3) âœ…**
* Architecture streaming IoT globale (**Apache Kafka**).
* Socle Cloud Native via **Microsoft Azure Kubernetes Service (AKS)**.
* DÃ©ploiement Data Engineer Zero-Touch par Infrastructure As Code (**Terraform**).
* CI/CD IntÃ©gral : SÃ©curitÃ© et Build poussÃ©s via **Azure Pipelines**.
* ObservabilitÃ© exÃ©cutif (Dashboarding) assurÃ© conjointement par **Grafana / Prometheus**.
* **Mode Local Bootstrap** : ExÃ©cution autonome sans PostgreSQL/Kafka.
* **Dashboard Streamlit** : Interface de dÃ©mo avec authentification API intÃ©grÃ©e.

**Version 3.0.0 (Vision Long Terme) ğŸ”®**
* ImplÃ©mentation complÃ¨te Digital Twin (Jumeau NumÃ©rique 3D) couplÃ© aux flux Kafka temps rÃ©el.

---

## ğŸ¤ CONTRIBUTION
L'Avenir passera par l'Intelligence de la DonnÃ©e Logistique :
1. Forker.
2. Proposer une implÃ©mentation `Prophet`/`LSTM`.
3. RÃ©aliser une Pull Request de GÃ©nie.

---

## ğŸ“„ LICENCE
Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique et hautement professionnel. Droits rÃ©servÃ©s.

## ğŸ‘¨â€ğŸ’» AUTEUR
**KAMENI TCHOUATCHEU GAETAN BRUNEL**  
IngÃ©nieur Logiciel & Data Scientist en devenir | Ã‰tudiant ESIEA  

ğŸ“§ Email : gaetanbrunel.kamenitchouatcheu@et.esiea.fr  
ğŸ™ GitHub : @Lkb-2905  

ğŸ™ **REMERCIEMENTS**
* **BollorÃ© Logistics & Camrail :** Pour l'envergure des architectures d'IngÃ©nierie de Haute Technologie.
* **ESIEA :** Pour l'esprit d'initiative.

â­ Laissez une Ã©toile pour soutenir le Full-Stack Data Engineering Camerounais !  
Fait avec â¤ï¸, Scikit et SQLAlchemy.  

Â© 2026 Kameni Tchouatcheu Gaetan Brunel - Tous droits rÃ©servÃ©s
