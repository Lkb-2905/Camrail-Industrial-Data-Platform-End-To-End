ğŸŒ DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
# âš¡ CIDP : Camrail Industrial Data Platform
![Terraform](https://img.shields.io/badge/Terraform-Infrastructure_As_Code-purple) ![Azure_DevOps](https://img.shields.io/badge/Azure_Pipelines-CI/CD-blue) ![Kubernetes](https://img.shields.io/badge/Kubernetes-AKS_Cluster-blue) ![Grafana](https://img.shields.io/badge/Grafana-SRE_Dashboards-orange)

**Version:** 3.0.0 Enterprise | **Date:** FÃ©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr  

ğŸš€ [DÃ©marrage Rapide](#-dÃ©marrage-rapide) â€¢ ğŸ“š [Documentation](#-guide-dutilisation) â€¢ ğŸ¯ [FonctionnalitÃ©s](#-fonctionnalitÃ©s-clÃ©s) â€¢ ğŸ”§ [Installation](#-installation-rapide)

---

## ğŸ“‹ TABLE DES MATIÃˆRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique](#ï¸-architecture-technique)
3. [Stack Technologique](#ï¸-stack-technologique)
4. [FonctionnalitÃ©s ClÃ©s](#-fonctionnalitÃ©s-clÃ©s)
5. [DÃ©marrage Rapide](#-dÃ©marrage-rapide)
6. [Guide d'Utilisation](#-guide-dutilisation)
7. [QualitÃ© & Best Practices](#-qualitÃ©--best-practices)
8. [Roadmap & Ã‰volutions](#ï¸-roadmap--Ã©volutions)

---

## ğŸ¯ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
L'**Industrial Data Platform (End-to-End)** dÃ©montre de magistrales capacitÃ©s d'architecture orientÃ©e *Data-Driven* globale. Ce projet hybride rÃ©unit l'IngÃ©nierie de la DonnÃ©e (ETL SQL) et la Data Science (Moteurs ML connectÃ©s Base de DonnÃ©es) dans une usine logicielle ferroviaire critique de grande ampleur.

Il illustre de A Ã  Z les compÃ©tences absolues suivantes :

âœ… **Architecture E2E Hexagonale :** Isolation de l'ETL (Extrait Moteur) et de la ML Data Science.
âœ… **Azure DevOps CI/CD :** Pipeline automatisÃ© des tests jusqu'au dÃ©ploiement (AKS).
âœ… **Infrastructure as Code (Terraform) :** Provisionnement complet et auditable de l'architecture Microsoft Azure.
âœ… **Kubernetes (AKS) :** Conteneurisation et auto-scaling horizontal de l'IA (API ML + Workers Kafka).
âœ… **ObservabilitÃ© Grafana / Prometheus :** Dashboards complets d'analyse des anomalies mÃ©tiers (SRE).
âœ… **Streaming IoT Temps RÃ©el (Kafka) :** Ingestion continue et asynchrone des flux capteurs massifs.
âœ… **Data Warehouse Cloud (PostgreSQL) :** Stockage relationnel lourd, robuste avec des capacitÃ©s gÃ©ospatiales.
âœ… **Mode Local (Bootstrap) :** ExÃ©cution autonome sans PostgreSQL/Kafka via `bootstrap_local.py` et API Flask.

### Pourquoi ce projet ?
| Aspect | DÃ©monstration |
| --- | --- |
| **ScalabilitÃ©** | L'Auto-Scaler Kubernetes multiplie les conteneurs API selon la charge Kafka. |
| **MaintenabilitÃ©** | L'Infrastructure `main.tf` permet un redÃ©ploiement complet en < 10min. |
| **Innovation** | Le CI/CD Azure Pipelines garantit 0 bug en production lors des upgrades IA. |
| **SÃ©curitÃ©** | Gestion Cloud Azure sÃ©curisant les connexions Pods / Database via Secrets K8s. API sÃ©curisÃ©e par `X-API-KEY` transmise dans le Dashboard Streamlit. |
| **Performance** | Monitoring visuel temps rÃ©el via Dashboards Grafana couplÃ©s Ã  Prometheus. |

---

## ğŸ—ï¸ ARCHITECTURE TECHNIQUE

### Diagramme de Flux (Vue Logique & Local)
```mermaid
flowchart TD
    %% Styling
    classDef client fill:#38bdf8,stroke:#0284c7,stroke-width:2px,color:#000
    classDef app fill:#4ade80,stroke:#16a34a,stroke-width:2px,color:#000
    classDef intel fill:#facc15,stroke:#ca8a04,stroke-width:2px,color:#000
    classDef data fill:#f87171,stroke:#dc2626,stroke-width:2px,color:#fff
    classDef darkBox fill:#27272a,stroke:#52525b,stroke-width:2px,color:#fff

    subgraph Client Layer
        O[ğŸ‘¤ OpÃ©rateur Logistique]:::darkBox -->|Pilotage| R[Streamlit Dashboard<br>Port 8501]:::client
    end

    subgraph Application Layer
        N[Flask API Backend<br>Port 5000]:::app
        S[Service MÃ©tier]:::darkBox
        N -->|Orchestration| S
    end

    subgraph Data Sources
        OM[Kafka / PostgreSQL<br>DonnÃ©es RÃ©elles]:::data
        SL[Simulateur Local<br>DonnÃ©es SynthÃ©tiques]:::darkBox
    end

    subgraph Intelligence Layer
        P[Python Engine<br>Scikit-Learn]:::intel
    end

    %% Connections
    R -->|HTTP GET/POST| N
    N -.->|API Request| OM
    N -->|Fallback| SL
    S -->|Shell / API Execution| P
    P -->|JSON Output| S

    %% Custom styles for Subgraphs
    style Client Layer fill:#3f3f46,stroke:#52525b,color:#fff
    style Application Layer fill:#3f3f46,stroke:#52525b,color:#fff
    style Data Sources fill:#3f3f46,stroke:#52525b,color:#fff
    style Intelligence Layer fill:#3f3f46,stroke:#52525b,color:#fff
```

### Architecture Infra (Cloud)

### Diagramme de Flux
```mermaid
graph TD
    subgraph Client Layer
        U[ğŸ‘¤ OpÃ©rateur Logistique]
        P[BI Dashboard Live]
        U -->|Pilotage| P
    end

    subgraph Azure DevOps CI/CD
        AZ[Pipeline Azure<br>Build, Test, Push]
    end

    subgraph Azure Kubernetes Service (AKS)
        K[Apache Kafka Broker]
        O[Microservice Consumer ETL]
        PR[Prometheus SRE]
        GF[Grafana Dashboards]
        M[API Flask ML Predict]
        
        K -->|Consumer Topic| O
        M -->|Exposition /metrics| PR
        PR -->|Data Source| GF
    end

    subgraph Infrastructure
        TF[Terraform IaC]
        AZ --> TF
        TF -.->|Provisioning| K
        TF -.->|Deploy| D
    end

    subgraph Data Sources
        S[Capteurs IoT Trains]
    end

    subgraph Cloud Postgres DB
        D[(PostgreSQL Flexible<br>Data Warehouse)]
    end

    S -->|Producteur Kafka| K
    O -->|Bulk Upsert| D
    D -->|Lecture DB| M
    M -->|JSON Response| P

    style P fill:#4FC3F7,color:#000
    style K fill:#FF9800,color:#fff
    style O fill:#4CAF50,color:#fff
    style M fill:#FFD600,color:#000
    style D fill:#336791,color:#fff
    style S fill:#FF5252,color:#fff
    style PR fill:#E6522C,color:#fff
    style GF fill:#F46800,color:#fff
    style AZ fill:#0078D7,color:#fff
    style TF fill:#844FBA,color:#fff
```

### Flux de DonnÃ©es DÃ©taillÃ©
1. **Infrastructure as Code** : Terraform instancie l'Event Hub, Azure Postgres et le Cluster Kubernetes de 0.
2. **DÃ©ploiement CI/CD** : Toute modification Master dÃ©clenche Azure DevOps qui compile l'image Docker, exÃ©cute `Pytest` et dÃ©ploie le YAML sur AKS.
3. **Architecture DistribuÃ©e (K8s)** : Les pods ETL capturent les Ã©vÃ¨nements Kafka et l'A.I API lit depuis la base Azure.
4. **Mode Local (Bootstrap)** : En absence de PostgreSQL/Kafka, `bootstrap_local.py` entraÃ®ne le modÃ¨le depuis les CSV (`data/sensors.csv`, `data/maintenance.csv`) et gÃ©nÃ¨re `models/latest.pkl`, permettant Ã  l'API et au Dashboard Streamlit de fonctionner en autonomie.
5. **Monitoring Ops (Grafana)** : Prometheus scrape les mÃ©triques (`/metrics`) du conteneur ML, que Grafana expose sous forme de Dashboard exÃ©cutif temps rÃ©el.
6. **Diffusion Live** : Dashboard Streamlit (port 8501) appelle l'API (port 5000) avec authentification `X-API-KEY` pour afficher les prÃ©dictions en temps rÃ©el.

---

## ğŸ› ï¸ STACK TECHNOLOGIQUE

### Technologies Core
| Composant | Technologie | Version | Justification Technique |
| --- | --- | --- | --- |
| **Infrastructure Cloud** | Terraform / Azure | Latest | DÃ©ploiement automatisÃ© (IaC) de l'usine logicielle complÃ¨te sur le Cloud Microsoft Azure. |
| **SGBD Cloud** | PostgreSQL | 15+ | Data Warehouse Enterprise-Grade pour stockage massif relationnel et analytique. |
| **Intelligence Artificielle**| Scikit-Learn | Latest | Algorithmes Random Forest industriels pour la maintenance prÃ©dictive. |
| **Orchestration & DevOps**| Kubernetes (AKS) | Latest | Auto-scaling des Pods API et des Workers Kafka via CI/CD Azure Pipelines. |
| **Dashboard Interactif** | Streamlit | Latest | Interface de dÃ©mo temps rÃ©el avec sliders (DÃ©bit, Pression, Vibration, TempÃ©rature) et appel API sÃ©curisÃ©. |

### BibliothÃ¨ques ComplÃ©mentaires
* **Loguru :** Remplacement intelligent du standard logger pour une traccabilitÃ© magistrale.
* **Pyenv :** Verrouillage strict de l'environnement Python utilisÃ©.
* **Pydantic :** Validation des payloads API et compatibilitÃ© v1/v2 (`.dict()` / `.model_dump()`).

---

## ğŸ¯ FONCTIONNALITÃ‰S CLÃ‰S

### ğŸš€ FonctionnalitÃ©s Principales
**Usine NumÃ©rique Cloud Native**
* DÃ©ploiement asynchrone orchestrÃ© par Terraform sur Azure Kubernetes Service. Supervision E2E Grafana.

**Algorithmes de Machine Learning sur PostgreSQL**
* Calcul des scores de risques vitaux enregistrÃ©s directement dans la base de donnÃ©es distante.

**Mode Local (Bootstrap)**
* Script `bootstrap_local.py` : entraÃ®nement du modÃ¨le depuis les CSV locaux â†’ `models/latest.pkl`. Permet une dÃ©mo complÃ¨te sans infrastructure Cloud.

**Dashboard Streamlit**
* Interface "Camrail Live Monitor" (localhost:8501) avec outil de test manuel : sliders pour simuler la tÃ©lÃ©mÃ©trie, bouton "Interroger l'API Neural Network", affichage "OPÃ‰RATION NOMINALE" ou "DANGER DÃ‰TECTÃ‰" selon les prÃ©dictions.

**MÃ©canismes SRE (Site Reliability Engineering)**
* Alerting Prometheus actif bloquant l'API si le modÃ¨le de Machine Learning diverge ou tombe en latence.

### ğŸ›¡ï¸ SÃ©curitÃ© & Robustesse
| Aspect | ImplÃ©mentation |
| --- | --- |
| **RÃ©silience Kubernetes** | Le Load Balancer Kubernetes reroute le flux en millisecondes si un Worker s'arrÃªte. |
| **SÃ©curitÃ© d'API** | Schema Validation via Pydantic et X-API-KEY intÃ©grÃ©e dans les Pods IA. Le Dashboard Streamlit transmet automatiquement le header `X-API-KEY` Ã  l'API Flask. |
| **TraÃ§abilitÃ© SRE** | Dashboard complet Grafana monitorant la santÃ© de chaque micro-service. |
| **Timeout & Erreurs** | Timeout API 15s, messages d'erreur explicites (API injoignable, ReadTimeout). |

---

## ğŸš€ DÃ‰MARRAGE RAPIDE

### PrÃ©requis
* Docker Desktop & Kubernetes (mode Cloud)
* Terraform Azure CLI (`az`) (mode Cloud)
* Python (v3.12+ pour le mode local)

### DÃ©ploiement Architecte (Cloud Microsoft Azure)
```bash
# 1. Provisionner l'infrastructure Cloud complÃ¨te
cd terraform
terraform init && terraform apply -auto-approve

# 2. Le CI/CD Azure DevOps compile et dÃ©ploie les Pods ML 
# sur AKS automatiquement au moindre push GitHub.
```

### Lancement DÃ©veloppeur (Mode Local â€” RecommandÃ© pour dÃ©mo)
```powershell
# 1. CrÃ©er l'environnement virtuel et installer les dÃ©pendances
cd Camrail-Industrial-Data-Platform
python -m venv .venv
.\.venv\Scripts\activate
pip install -r requirements.txt

# 2. Bootstrap du modÃ¨le (entraÃ®nement depuis CSV)
$env:PYTHONPATH = (Get-Location).Path
python bootstrap_local.py

# 3. DÃ©marrer l'API Flask (Terminal 1)
python api/api.py

# 4. DÃ©marrer le Dashboard Streamlit (Terminal 2)
streamlit run dashboard/app.py
```

**AccÃ¨s ImmÃ©diat :**
* API : **http://127.0.0.1:5000** (GET `/health`, POST `/predict` avec header `X-API-KEY: entreprise_secret_key_2026`)
* Dashboard : **http://localhost:8501** â€” Camrail Live Monitor

### Lancement Mode Complet (PostgreSQL + Kafka)
```bash
python run_platform.py
```

---

## ğŸ“– GUIDE D'UTILISATION

### ScÃ©nario de Pilotage
1. **Lancement Kafka & Microservices :** Laissez les Deployments Kubernetes assurer l'ingestion asynchrone IoT.
2. **Supervision BI ConnectÃ©e :** En utilisant le connecteur DirectQuery PostgreSQL, connectez vos outils Power BI/Grafana pour surveiller la santÃ© des locomotives Ã  la seconde prÃ¨s.
3. **DÃ©mo Recruteur :** Lancer l'API + Dashboard, afficher le cas nominal (Vibration 2, TempÃ©rature 45), puis simuler une alerte (Vibration 7+, TempÃ©rature 85+) et montrer le message "DANGER DÃ‰TECTÃ‰".

### Captures d'Ã‰cran
**ğŸ“¸ RÃ©sultat de l'exÃ©cution (Local)**  
![ExÃ©cution Local](execution_screenshot.png)

**ğŸ“¸ Dashboard Streamlit â€” Vue gÃ©nÃ©rale**  
![Camrail Live Monitor](../docs/screenshots/01_cidp_dashboard_vue_generale.png)

**ğŸ“¸ Cas nominal â€” OpÃ©ration normale**  
![OpÃ©ration nominale](../docs/screenshots/01_cidp_dashboard_vue_generale.png)

**ğŸ“¸ Cas alerte â€” Danger dÃ©tectÃ©**  
![Alerte danger](../docs/screenshots/02_cidp_dashboard_alerte_danger.png)

**ğŸ“¸ Bootstrap et dÃ©marrage API**  
![Bootstrap et API](../docs/screenshots/04_cidp_bootstrap_api_demarrage.png)

> ğŸ’¡ Convention de nommage des captures : voir `../docs/screenshots/README.md`

---

## âœ¨ QUALITÃ‰ & BEST PRACTICES

### Standards de Code
* **ModularitÃ© (Hexagonale) :** Couches rÃ©parties avec rigueur.
* **Clean Code Data :** L'intelligence ne pervertit pas les couches basses, la connexion est une API via SGBD.
* **Error Handling :** Exception Management `try-except sys.exit(1)` garantissant la puretÃ© du pipeline.
* **CompatibilitÃ© Pydantic :** Gestion transparente Pydantic v1 et v2 pour les payloads API.

### MÃ©triques d'Excellence
âœ… **Couverture fonctionnelle :** L'ExtrÃªme bout-en-bout d'une compÃ©tence d'IngÃ©nieur Full-Stack Data en action.
âœ… **Performance globale :** Architecture `Zero-Downtime` SQL SupportÃ©e.
âœ… **Tests automatisÃ©s :** `pytest tests/test_api.py` â€” 4 tests (health, unauthorized, schema validation, bad method).

---

## ğŸ—ºï¸ ROADMAP & Ã‰VOLUTIONS

**Version Actuelle : 3.0.0 (Enterprise V3) âœ…**
* Architecture streaming IoT globale (**Apache Kafka**).
* Socle Cloud Native via **Microsoft Azure Kubernetes Service (AKS)**.
* DÃ©ploiement Data Engineer Zero-Touch par Infrastructure As Code (**Terraform**).
* CI/CD IntÃ©gral : SÃ©curitÃ© et Build poussÃ©s via **Azure Pipelines**.
* ObservabilitÃ© exÃ©cutif (Dashboarding) assurÃ© conjointement par **Grafana / Prometheus**.
* **Mode Local Bootstrap** : ExÃ©cution autonome sans PostgreSQL/Kafka.
* **Dashboard Streamlit** : Interface de dÃ©mo avec authentification API intÃ©grÃ©e.

**Version 3.0.0 (Vision Long Terme) ğŸ”®**
* ImplÃ©mentation complÃ¨te Digital Twin (Jumeau NumÃ©rique 3D) couplÃ© aux flux Kafka temps rÃ©el.

---

## ğŸ¤ CONTRIBUTION
L'Avenir passera par l'Intelligence de la DonnÃ©e Logistique :
1. Forker.
2. Proposer une implÃ©mentation `Prophet`/`LSTM`.
3. RÃ©aliser une Pull Request de GÃ©nie.

---

## ğŸ“„ LICENCE
Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique et hautement professionnel. Droits rÃ©servÃ©s.

## ğŸ‘¨â€ğŸ’» AUTEUR
**KAMENI TCHOUATCHEU GAETAN BRUNEL**  
IngÃ©nieur Logiciel & Data Scientist en devenir | Ã‰tudiant ESIEA  

ğŸ“§ Email : gaetanbrunel.kamenitchouatcheu@et.esiea.fr  
ğŸ™ GitHub : @Lkb-2905  

ğŸ™ **REMERCIEMENTS**
* **BollorÃ© Logistics & Camrail :** Pour l'envergure des architectures d'IngÃ©nierie de Haute Technologie.
* **ESIEA :** Pour l'esprit d'initiative.

â­ Laissez une Ã©toile pour soutenir le Full-Stack Data Engineering Camerounais !  
Fait avec â¤ï¸, Scikit et SQLAlchemy.  

Â© 2026 Kameni Tchouatcheu Gaetan Brunel - Tous droits rÃ©servÃ©s
