üåç DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
# ‚ö° DPA PCR : Data Pipeline Automation (S√©curit√© E2E)
![S√©curit√©](https://img.shields.io/badge/Plan-Continuit√©-red) ![ETL](https://img.shields.io/badge/ETL-Resilience-blue) ![Qualit√©](https://img.shields.io/badge/Qualit√©-ISO27001-yellow)

**Version:** 2.0.0 Enterprise | **Date:** F√©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr  

---

## üìã TABLE DES MATI√àRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique (Menaces)](#Ô∏è-architecture-technique)
3. [Stack Technologique & PCA](#Ô∏è-stack-technologique)
4. [Fonctionnalit√©s Cl√©s (Reprise PRA)](#-fonctionnalit√©s-cl√©s)
5. [D√©marrage Rapide (Secours)](#-d√©marrage-rapide)
6. [Qualit√© & Best Practices](#-qualit√©--best-practices)

---

## üéØ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
Ce document d√©finit la strat√©gie compl√®te de r√©silience op√©rationnelle et le **Plan de Continuit√© d'Activit√© (PCA)** du pipeline ETL Supply Chain, incluant les flux API/JSON, CSV, Excel et le Data Warehouse SQLite.

Il illustre de A √† Z les comp√©tences absolues suivantes :

‚úÖ **Fail-Safe ETL :** Tol√©rance aux corruptions partielles de fichiers (CSV, JSON, Excel). Le pipeline ne plante pas en cas de source d√©grad√©e.
‚úÖ **Validation & Rollback :** SQLAlchemy transactions avec rollback automatique en cas d'√©chec de chargement.
‚úÖ **Multi-Source :** Fallback Excel (`extract_from_excel`) si les sources API/CSV sont indisponibles.
‚úÖ **Export Contr√¥l√© :** Rapport Excel multi-feuilles g√©n√©r√© de fa√ßon atomique dans `reports/`.

---

## üèóÔ∏è ARCHITECTURE TECHNIQUE

### Flux de Donn√©es D√©taill√© (BIA - Business Impact Analysis)
| Menace Identifi√©e | Probabilit√© | Impact M√©tier | S√©v√©rit√© |
| --- | --- | --- | --- |
| **API JSON indisponible** | Moyenne (2/5) | Utilisation de la source Excel ou CSV ERP en fallback | üü¢ Mineur |
| **Fichier CSV/Excel corrompu** | Moyenne (2/5) | Parsing strict, skip des lignes invalides, logs d√©taill√©s | üü† Moyen |
| **Base SQLite verrouill√©e** | Faible (1/5) | Rollback transaction, retry ou report manuel | üü† Moyen |
| **Export Excel √©chou√©** | Faible (1/5) | DWH SQLite reste intact ; export manuel possible via `excel_utils` | üü¢ Mineur |
| **Perte du DWH** | Tr√®s faible | Reprise depuis sources brutes (data_raw, Excel) et relance `main_pipeline.py` | üî¥ Critique (PRA) |

---

## üõ†Ô∏è STACK TECHNOLOGIQUE

### Strat√©gies de Continuit√© (PCA)
* **Transaction atomique :** Les insertions SQLite passent par SQLAlchemy avec commits/rollbacks contr√¥l√©s.
* **Multi-source :** En cas d'indisponibilit√© des APIs, le pipeline peut s'alimenter depuis Excel (`extract_from_excel`) ou les fichiers CSV locaux.
* **Export non bloquant :** L'export Excel vers `reports/rapport_supply_chain.xlsx` n'impacte pas l'int√©grit√© du DWH en cas d'√©chec.

---

## üéØ FONCTIONNALIT√âS CL√âS

### üöÄ Proc√©dures de Reprise (PRA)
**Reprise apr√®s perte du Data Warehouse**
```powershell
# 1. V√©rifier la pr√©sence des sources
dir Data-Pipeline-Automation\data_raw
dir exemples_excel_access\output   # Si source Excel utilis√©e

# 2. Relancer le pipeline complet
cd Data-Pipeline-Automation\src
python main_pipeline.py

# 3. Le DWH est recr√©√© et l'export Excel r√©g√©n√©r√©
```

**Export manuel en cas d'√©chec automatique**
```python
from utils.excel_utils import export_dwh_to_excel
export_dwh_to_excel("database/supply_chain_dwh.sqlite", "reports/rapport_supply_chain.xlsx")
```

### üõ°Ô∏è S√©curit√© & Robustesse
| Aspect | Impl√©mentation |
| --- | --- |
| **Validation donn√©es** | Parsing strict Pandas, v√©rification des types avant insert. |
| **R√©silience SQL** | Transactions SQLAlchemy, pas de SQL direct en param√®tre (ORM). |
| **Tra√ßabilit√©** | Loguru logs exhaustifs (ex√©cution, erreurs, lignes ignor√©es). |
| **Sources Excel/Access** | Gestion des erreurs ODBC (pyodbc), fallback si pilote manquant. |

---

## üöÄ D√âMARRAGE RAPIDE (MODE SECOURS LOCAL)

### Red√©marrage du pipeline ETL (sources locales uniquement)
Sans acc√®s API Cloud, le pipeline s'ex√©cute enti√®rement en local.
```powershell
cd Data-Pipeline-Automation\src
python main_pipeline.py
# Sources : data_raw/*.json, data_raw/*.csv
# R√©sultat : database/supply_chain_dwh.sqlite + reports/rapport_supply_chain.xlsx
```

### Mode fallback Excel
Si les fichiers JSON/CSV standards sont absents ou corrompus :
```python
# Dans extract.py ou script custom
from extract import extract_from_excel
api_data, erp_data = extract_from_excel("chemin/vers/transactions.xlsx")
# Puis transform_data() et load_data()
```

### R√©f√©rences visuelles
![Ex√©cution Pipeline ETL](../docs/screenshots/05_dpa_pipeline_execution.png)  
![Base DWH SQLite](../docs/screenshots/06_dpa_sqlite_dwh.png)

---

## ‚ú® QUALIT√â & BEST PRACTICES

### M√©triques d'Excellence
‚úÖ **Atomicit√© :** Chargement DWH tout-ou-rien (rollback sur erreur).
‚úÖ **Auditabilit√© :** Loguru conserve la rotation des traces (10 MB/30 Days).
‚úÖ **Portabilit√© :** SQLite + Excel permettent un d√©ploiement sans infrastructure Cloud.

---
Ce projet est Confidentiel. R√©serv√© √† un usage acad√©mique et professionnel rigoureux.  
¬© 2026 Kameni Tchouatcheu Gaetan Brunel - Tous droits r√©serv√©s
