ğŸŒ DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
# âš¡ DPA : Data Pipeline Automation
![Terraform](https://img.shields.io/badge/Terraform-IaC-purple) ![Azure](https://img.shields.io/badge/Azure_Pipelines-CI/CD-blue) ![Kubernetes](https://img.shields.io/badge/Kubernetes-Data_Pods-blue) ![Grafana](https://img.shields.io/badge/Grafana-SRE_Dashboards-orange)

**Version:** 1.0.0 Stable | **Date:** FÃ©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr  

ğŸš€ [DÃ©marrage Rapide](#-dÃ©marrage-rapide) â€¢ ğŸ“š [Documentation](#-guide-dutilisation) â€¢ ğŸ¯ [FonctionnalitÃ©s](#-fonctionnalitÃ©s-clÃ©s) â€¢ ğŸ”§ [Installation](#-installation-rapide)

---

## ğŸ“‹ TABLE DES MATIÃˆRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique](#ï¸-architecture-technique)
3. [Stack Technologique](#ï¸-stack-technologique)
4. [FonctionnalitÃ©s ClÃ©s](#-fonctionnalitÃ©s-clÃ©s)
5. [DÃ©marrage Rapide](#-dÃ©marrage-rapide)
6. [Guide d'Utilisation](#-guide-dutilisation)
7. [QualitÃ© & Best Practices](#-qualitÃ©--best-practices)
8. [Roadmap & Ã‰volutions](#ï¸-roadmap--Ã©volutions)

---

## ğŸ¯ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
Ce projet illustre l'implÃ©mentation robuste d'une architecture **Data-Driven (ETL)** pour le pilotage logistique des donnÃ©es de fret. Il rÃ©pond aux exigences d'une gouvernance informatique moderne en unifiant les donnÃ©es, les fichiers Ã©pars et les signaux mÃ©tiers.

Il illustre les compÃ©tences suivantes :

âœ… **Azure DevOps CI/CD :** Pipeline automatisÃ© des tests jusqu'au dÃ©ploiement (AKS).
âœ… **Infrastructure as Code (Terraform) :** Provisionnement complet et auditable de l'architecture Microsoft Azure.
âœ… **Kubernetes (AKS) :** Conteneurisation et auto-scaling horizontal des pods ETL.
âœ… **ObservabilitÃ© Grafana / Prometheus :** Dashboards complets d'analyse des flux de donnÃ©es.
âœ… **Streaming Asynchrone (Kafka) :** Les signaux logistiques sont bufferisÃ©s via topics.
âœ… **Data Warehouse Cloud (PostgreSQL) :** Stockage sÃ©curisÃ© et hautement performant sur Microsoft Azure.

### Pourquoi ce projet ?
| Aspect | DÃ©monstration |
| --- | --- |
| **ScalabilitÃ©** | L'Auto-Scaler Kubernetes multiplie les conteneurs ETL selon la charge de donnÃ©es arrivant dans Kafka. |
| **MaintenabilitÃ©** | L'Infrastructure `main.tf` (Terraform) permet de cloner l'environnement de production sur Azure en quelques minutes. |
| **Innovation** | Le CI/CD Azure Pipelines garantit 0 bug en production lors des dÃ©ploiements logistiques. |
| **SÃ©curitÃ©** | Gestion Cloud Azure sÃ©curisant les connexions Pods / Database via Secrets et authentifications fortes. |
| **Business Value** | Dote les gestionnaires de KPI calculÃ©s et requÃªtes avancÃ©es (Data Warehouse Azure). |

---

## ğŸ—ï¸ ARCHITECTURE TECHNIQUE

### Diagramme de Flux (Vue Logique & ETL Local)
```mermaid
flowchart TD
    %% Styling
    classDef client fill:#38bdf8,stroke:#0284c7,stroke-width:2px,color:#000
    classDef app fill:#4ade80,stroke:#16a34a,stroke-width:2px,color:#000
    classDef intel fill:#facc15,stroke:#ca8a04,stroke-width:2px,color:#000
    classDef data fill:#f87171,stroke:#dc2626,stroke-width:2px,color:#fff
    classDef darkBox fill:#27272a,stroke:#52525b,stroke-width:2px,color:#fff

    subgraph Client Layer
        O[ğŸ‘¤ OpÃ©rateur Logistique]:::darkBox -->|Pilotage| R[Dashboard BI / DBeaver<br>SQL Analytics]:::client
    end

    subgraph Application Layer
        N[Python ETL Pipeline<br>main_pipeline.py]:::app
        S[Data Warehouse<br>SQLite / SQlAlchemy]:::darkBox
        N -->|Orchestration| S
    end

    subgraph Data Sources
        OM[Kafka / Azure SQL<br>DonnÃ©es Cloud]:::data
        SL[Sources Locales<br>CSVs / JSONs / Excel]:::darkBox
    end

    subgraph Intelligence Layer
        P[Python Transform<br>Pandas Analytics]:::intel
    end

    %% Connections
    R -->|RequÃªtes SQL| S
    N -.->|Extract Cloud| OM
    N -->|Extract Local| SL
    N -->|Transformation| P
    P -->|Dataframes Propres| N
    N -->|Load (SQL Insert)| S

    %% Custom styles for Subgraphs
    style Client Layer fill:#3f3f46,stroke:#52525b,color:#fff
    style Application Layer fill:#3f3f46,stroke:#52525b,color:#fff
    style Data Sources fill:#3f3f46,stroke:#52525b,color:#fff
    style Intelligence Layer fill:#3f3f46,stroke:#52525b,color:#fff
```

### Architecture Infra (Cloud)
```mermaid
graph TD
    subgraph Client Layer
        U[ğŸ‘¤ DÃ©cideur Supply Chain]
        P[DBeaver / Dashboard BI]
        U -->|Pilotage| P
    end

    subgraph Azure DevOps CI/CD
        AZ[Pipeline Azure<br>Build, Test, Push]
    end

    subgraph Azure Kubernetes Service (AKS)
        K[Apache Kafka Cluster]
        E[Extracteur API JSON]
        T[Transformateur Pandas]
        L[Worker SQLAlchemy]
        PR[Prometheus SRE]
        GF[Grafana Dashboards]
        K -->|Consumer Topic| E
        E -->|Nettoyage| T
        T -->|Manipulation| L
        L -->|Metriques SantÃ©| PR
        PR -->|Data Source| GF
    end

    subgraph Infrastructure
        TF[Terraform IaC]
        AZ --> TF
        TF -.->|Provisioning| K
        TF -.->|Deploy| D
    end

    subgraph Data Sources
        S[Terminaux Logistiques Fret]
    end

    subgraph Cloud PostgreSQL
        D[(Azure PostgreSQL<br>Data Warehouse)]
    end

    S -->|Producteur Kafka| K
    L -->|Upsert SQL/Bulk| D
    D -->|RequÃªtes Analytiques| P

    style P fill:#4FC3F7,color:#000
    style K fill:#FF9800,color:#fff
    style E fill:#4CAF50,color:#fff
    style T fill:#4CAF50,color:#fff
    style L fill:#4CAF50,color:#fff
    style D fill:#336791,color:#fff
    style S fill:#FF5252,color:#fff
    style PR fill:#E6522C,color:#fff
    style GF fill:#F46800,color:#fff
    style AZ fill:#0078D7,color:#fff
    style TF fill:#844FBA,color:#fff
```

### Flux de DonnÃ©es DÃ©taillÃ©
1. **Infrastructure as Code** : Terraform instancie Microsoft Azure PostgreSQL, Event Hubs et AKS.
2. **DÃ©ploiement CI/CD** : Azure DevOps compile et pousse l'image Docker ETL vers AKS pour son exÃ©cution en Pods.
3. **Extraction & Transformation (K8s)** : Les micro-services rÃ©cupÃ¨rent la donnÃ©e Kafka en direct et fusionnent les tables via Pandas.
4. **Chargement SQL & SRE** : Les donnÃ©es sont chargÃ©es en Bulk Upsert sur Azure Postgres. Prometheus et Grafana monitorent le flux de santÃ© absolu de l'architecture Big Data.

---

## ğŸ› ï¸ STACK TECHNOLOGIQUE

### Technologies Core
| Composant | Technologie | Version | Justification Technique |
| --- | --- | --- | --- |
| **Orchestrateur** | Python | 3.12+ | L'outil complet de traitement universel par batch d'ingÃ©nierie. |
| **Base de DonnÃ©es** | SQLite | 3+ | DWH de fichier ultra-lÃ©ger et transportable localement. |
| **Data Engine** | Pandas | Latest | Traitement et jointure rapide de la donnÃ©e en RAM. |
| **ORM et Mapping** | SQLAlchemy | Latest | ConnectivitÃ© et sÃ©curitÃ© des transactions SQL (pas de SQL syntax direct en paramÃ¨tre mÃ©tier). |

### BibliothÃ¨ques ComplÃ©mentaires
* **Loguru/Logging :** TraÃ§abilitÃ© exhaustive.
* **Openpyxl :** Lecture/Ã©criture Excel (source ERP, export rapports).
* **PyODBC :** Connexion Microsoft Access (bases legacy, migration).
* **OS/Sys :** Commandes natives utiles Ã  l'interaction Windows (Task Scheduler).

---

## ğŸ¯ FONCTIONNALITÃ‰S CLÃ‰S

### ğŸš€ FonctionnalitÃ©s Principales
**Gouvernance Data Temps RÃ©el**
* Consolidations des flux Ã©pars vers une Base Unique.
* CrÃ©ation propre et persistante de `supply_chain_dwh.sqlite`.

**SystÃ¨me AvancÃ© de RequÃªtage**
* DÃ©ploiement de scripts SQL analytiques poussÃ©s pour catÃ©goriser la fiabilitÃ© du systÃ¨me (Hub Logistics Classification).

**Gestion des Risques**
* TolÃ©rance du Pipeline en mode fail-safe sur corruption partielle de fichier.

### ğŸ›¡ï¸ SÃ©curitÃ© & Robustesse
| Aspect | ImplÃ©mentation |
| --- | --- |
| **Validation** | VÃ©rification et parsing stricts avant transaction. |
| **RÃ©silience** | Base de donnÃ©es SQL protÃ©gÃ©e des deadlocks et Ã©checs (Rollbacks). |
| **TraÃ§abilitÃ©** | Logs dÃ©taillÃ©s sur serveurs ou scripts chronologiques. |

---

## ğŸš€ DÃ‰MARRAGE RAPIDE

### PrÃ©requis
* Python (v3.12+)

### Installation Rapide
```powershell
# 1. Cloner le projet (Naviguer au sein du rÃ©pertoire)
cd Data-Pipeline-Automation

# 2. Installer les dÃ©pendances
pip install -r requirements.txt

# 3. Lancer l'Orchestrateur Complet
cd src
python main_pipeline.py
```
**AccÃ¨s ImmÃ©diat :** Les tables historiques sont fraÃ®ches et disponibles instantanÃ©ment dans `database/supply_chain_dwh.sqlite`.

---

## ğŸ“– GUIDE D'UTILISATION

### ScÃ©nario de Pilotage
1. **Lancement Quotidien :** L'outil tourne la nuit via scheduler.
2. **RequÃªtage Expert :** Un Data Analyst peut soumettre `sql/advanced_queries.sql` au DBeaver de la base.
3. **Action:** Construction de Dashboard et exports mÃ©tier sur l'activitÃ© des "Gares".

### Captures d'Ã‰cran
**ğŸ“¸ RÃ©sultat de l'exÃ©cution (Local)**  
![ExÃ©cution Local](execution_screenshot.png)

**ğŸ“¸ ExÃ©cution du Pipeline ETL**  
![ExÃ©cution du Pipeline ETL](../docs/screenshots/05_dpa_pipeline_execution.png)

**ğŸ“¸ Base de donnÃ©es DWH SQLite**  
![Base SQLite Supply Chain](../docs/screenshots/06_dpa_sqlite_dwh.png)

> ğŸ’¡ Convention de nommage : voir `../docs/screenshots/README.md`

---

## âœ¨ QUALITÃ‰ & BEST PRACTICES

### Standards de Code
* **ModularitÃ© (Engine) :** Couches E, T, et L isolÃ©es nativement.
* **Typage (Data) :** Cast structurÃ©s au sein des Dataframes.
* **Error Handling :** Blocs robustes limitant l'Ã©crasement bdd en cas de corruption.

### MÃ©triques d'Excellence
âœ… **Architecture :** DWH Single Source of Truth respectÃ© (SSOT).
âœ… **Performance :** L'ORM insÃ¨re des dizaines de milliers de lignes en lots optimisÃ©s (bulk).

---

## ğŸ—ºï¸ ROADMAP & Ã‰VOLUTIONS

**Version Actuelle : 2.0.0 (Enterprise V2) âœ…**
* Architecture Data Streaming en Event-Driven via Apache Kafka.
* Virtualisation Globale : Orchestration via Docker Compose complet.
* Base de DonnÃ©es : Connecteur vers Cloud Azure PostgreSQL et Prometheus SRE.
* Documentation exhaustive DCE.

**Version 3.0.0 (Vision Long Terme) ğŸ”®**
* ImplÃ©mentation de Streaming Machine Learning Temps RÃ©el.

---

## ğŸ¤ CONTRIBUTION
Les contributions sont les bienvenues pour industrialiser ce socle mÃ©tier logistique.
1. Forker.
2. DÃ©finir une Feature Branche.
3. Valider par PR documentÃ©e.

---

## ğŸ“„ LICENCE
Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique et professionnel. Droits rÃ©servÃ©s.

## ğŸ‘¨â€ğŸ’» AUTEUR
**KAMENI TCHOUATCHEU GAETAN BRUNEL**  
IngÃ©nieur Logiciel & Data Scientist en devenir | Ã‰tudiant ESIEA  

ğŸ“§ Email : gaetanbrunel.kamenitchouatcheu@et.esiea.fr  
ğŸ™ GitHub : @Lkb-2905  

ğŸ™ **REMERCIEMENTS**
* **Camrail / BollorÃ© Logistics :** Pour l'approche industrielle robuste Data Management.
* **ESIEA :** Pour l'excellence informatique et acadÃ©mique.

â­ Si ce projet vous semble pertinent pour la Supply Chain de demain, laissez une Ã©toile !  
Fait avec â¤ï¸, Python et du SQL.  

Â© 2026 Kameni Tchouatcheu Gaetan Brunel - Tous droits rÃ©servÃ©s
