üåç DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
# ‚ö° CAMRAIL : Cha√Æne Logistique Ferroviaire & Maintenance Pr√©dictive
![Python](https://img.shields.io/badge/Python-3.12+-green) ![Flask](https://img.shields.io/badge/Flask-API_REST-blue) ![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-orange) ![Data_Science](https://img.shields.io/badge/Data_Science-Random_Forest-red) ![Kafka](https://img.shields.io/badge/Kafka-Streaming-purple)

**Version:** 3.0.0 Enterprise | **Date:** F√©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr  

üöÄ [D√©marrage Rapide](#-d√©marrage-rapide) ‚Ä¢ üìö [Documentation](#-guide-dutilisation) ‚Ä¢ üéØ [Fonctionnalit√©s](#-fonctionnalit√©s-cl√©s) ‚Ä¢ üîß [Installation](#-installation-compl√®te)

---

## üìã TABLE DES MATI√àRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique](#Ô∏è-architecture-technique)
3. [Stack Technologique](#Ô∏è-stack-technologique)
4. [Fonctionnalit√©s Cl√©s](#-fonctionnalit√©s-cl√©s)
5. [D√©marrage Rapide](#-d√©marrage-rapide)
6. [Installation Compl√®te](#-installation-compl√®te)
7. [Guide d'Utilisation](#-guide-dutilisation)
8. [API Documentation](#-api-documentation)
9. [Qualit√© & Best Practices](#-qualit√©--best-practices)
10. [Roadmap & √âvolutions](#Ô∏è-roadmap--√©volutions)

---

## üéØ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
Ce projet d√©montre la mise en ≈ìuvre d'une architecture orient√©e **Data-Driven** pour le pilotage logistique ferroviaire (Camrail / Bollor√© Logistics). Il r√©pond aux exigences de la Supply Chain moderne en combinant ETL, maintenance pr√©dictive par l'IA et supervision temps r√©el.

Il illustre les comp√©tences suivantes :

‚úÖ **Architecture D√©coupl√©e :** S√©paration stricte ETL (Pandas) / API ML (Flask) / Dashboard (Streamlit).
‚úÖ **Data Science Int√©gr√©e :** Moteur pr√©dictif Scikit-Learn (Random Forest) pour la maintenance pr√©dictive des locomotives.
‚úÖ **API RESTful :** Endpoints robustes avec validation Pydantic et authentification X-API-KEY.
‚úÖ **UX Moderne :** Interface de pilotage r√©active (Streamlit) avec sliders et feedback temps r√©el.
‚úÖ **Industrialisation :** Plan de Continuit√© (PCR) dans chaque sous-projet (`DOSSIER_SECURITE_CONTINUITE_PCR.md`), documentation DCE, sp√©cifications Power BI.
‚úÖ **Excel / Access :** Int√©gration bureautique ‚Äî import Excel (source ERP), export rapports, lecture Access (voir `exemples_excel_access/`).
‚úÖ **Clean Code :** Modularit√©, tests automatis√©s (Pytest), compatibilit√© Pydantic v1/v2.

### Pourquoi ce projet ?
| Aspect | D√©monstration |
| --- | --- |
| **Scalabilit√©** | Architecture pr√™te pour Kafka, PostgreSQL et Kubernetes (AKS). |
| **Maintenabilit√©** | Code modulaire avec s√©paration ETL / ML / API / Dashboard. |
| **Innovation** | Hybride unique entre pipeline ETL, Data Science et monitoring temps r√©el. |
| **S√©curit√©** | X-API-KEY, validation Pydantic, secrets injectables. |
| **Performance** | Mod√®le ML s√©rialis√© (Joblib), chargement asynchrone, mode bootstrap local. |

---

## üèóÔ∏è ARCHITECTURE TECHNIQUE

### Diagramme de Flux
```mermaid
flowchart TD
    classDef client fill:#38bdf8,stroke:#0284c7,stroke-width:2px,color:#000
    classDef app fill:#4ade80,stroke:#16a34a,stroke-width:2px,color:#000
    classDef intel fill:#facc15,stroke:#ca8a04,stroke-width:2px,color:#000
    classDef data fill:#f87171,stroke:#dc2626,stroke-width:2px,color:#fff
    classDef darkBox fill:#27272a,stroke:#52525b,stroke-width:2px,color:#fff

    subgraph Client_Layer["Client Layer"]
        O[üë§ Op√©rateur Logistique]:::darkBox -->|Pilotage| R[Streamlit Dashboard<br>Port 8501]:::client
    end

    subgraph Application_Layer["Application Layer"]
        N[Flask API Backend<br>Port 5000]:::app
        S[Service M√©tier<br>DPA ‚Ä¢ PM-D]:::darkBox
        R -->|HTTP GET/POST| N
        N -->|API Request| OM
        N -->|Fallback| SL
        N -->|Orchestration| S
    end

    subgraph Data_Sources["Data Sources"]
        OM[Kafka / PostgreSQL<br>API JSON Donn√©es R√©elles]:::data
        SL[Simulateur Local<br>CSV / Excel Synth√©tiques]:::data
        SL -.-> OM
    end

    subgraph Intelligence_Layer["Intelligence Layer"]
        P[Python Engine<br>Scikit-Learn Random Forest]:::intel
    end

    S -->|Shell Execution| P
    P -->|JSON Output| S

    style Client_Layer fill:#3f3f46,stroke:#52525b,color:#fff
    style Application_Layer fill:#3f3f46,stroke:#52525b,color:#fff
    style Data_Sources fill:#3f3f46,stroke:#52525b,color:#fff
    style Intelligence_Layer fill:#3f3f46,stroke:#52525b,color:#fff
```

**R√©sultat visuel ‚Äî Captures par composant :**
| DPA | CIDP | PM-D |
| --- | --- | --- |
| [Pipeline](docs/screenshots/05_dpa_pipeline_execution.png) ‚Ä¢ [DWH](docs/screenshots/06_dpa_sqlite_dwh.png) | [Vue](docs/screenshots/01_cidp_dashboard_vue_generale.png) ‚Ä¢ [Alerte](docs/screenshots/02_cidp_dashboard_alerte_danger.png) ‚Ä¢ [D√©pannage](docs/screenshots/09_cidp_dashboard_error_timeout.png) | [G√©n√©ration](docs/screenshots/07_pmd_generation_donnees.png) ‚Ä¢ [Training](docs/screenshots/08_pmd_model_training.png) |

### Flux de Donn√©es D√©taill√©
1. **Extraction (DPA) :** Donn√©es API JSON et ERP CSV ‚Üí transformation Pandas ‚Üí chargement SQLite.
2. **Pr√©diction (CIDP) :** Bootstrap ou PostgreSQL ‚Üí entra√Ænement Random Forest ‚Üí `models/latest.pkl`.
3. **Supervision :** Dashboard Streamlit appelle l'API `/predict` avec t√©l√©m√©trie simul√©e (sliders).
4. **Maintenance (PM-D) :** G√©n√©ration t√©l√©m√©trie ‚Üí feature engineering ‚Üí entra√Ænement mod√®le ‚Üí s√©rialisation Joblib.

---

## üõ†Ô∏è STACK TECHNOLOGIQUE

### Technologies Core
| Composant | Technologie | Version | Justification Technique |
| --- | --- | --- | --- |
| **Langage** | Python | 3.12+ | Standard Data Science, ETL, ML. |
| **API** | Flask | 3.x | Endpoints REST, int√©gration Prometheus. |
| **Dashboard** | Streamlit | Latest | Interface r√©active, d√©mo temps r√©el. |
| **Data AI** | Scikit-Learn | Latest | Random Forest pour maintenance pr√©dictive. |
| **ETL** | Pandas | Latest | Manipulation vectorielle, jointures, agr√©gations. |
| **Base** | SQLite / PostgreSQL | 3+ / 15+ | DWH l√©ger (local) ou Cloud. |

### Biblioth√®ques Compl√©mentaires
* **Pydantic :** Validation des payloads API (compatibilit√© v1/v2).
* **Loguru :** Logging structur√© avec rotation (10 MB / 30 jours).
* **Joblib :** S√©rialisation rapide des mod√®les ML.
* **Prometheus_client :** M√©triques SRE pour orchestrateurs.

---

## üéØ FONCTIONNALIT√âS CL√âS

### üöÄ Fonctionnalit√©s Principales

**Supervision Temps R√©el (CIDP)**
* Suivi des KPIs : D√©bit d'huile, Pression, Vibrations, Temp√©rature.
* Dashboard Streamlit "Camrail Live Monitor" avec test manuel API.
* Affichage "OP√âRATION NOMINALE" ou "DANGER D√âTECT√â" selon les pr√©dictions.

**Intelligence Artificielle Pr√©dictive**
* Mod√®le Random Forest pour d√©tecter les risques de panne imminente.
* Mode bootstrap local (entra√Ænement depuis CSV sans PostgreSQL/Kafka).
* Probabilit√© de risque et score binaire expos√©s via l'API.

**Gestion des Risques**
* D√©tection automatique des signatures m√©triques alarmantes.
* Alertes visuelles (banni√®re rouge) et taux de fiabilit√© machine.

**Reporting & DWH**
* Pipeline ETL (DPA) : `fact_transactions`, `aggr_daily_site_stats`.
* **Export Excel** automatique vers `reports/rapport_supply_chain.xlsx` (multi-feuilles).
* **Excel / Access :** Lecture Excel comme source, export pour import Access. Exemples dans `exemples_excel_access/`.
* Sp√©cifications Power BI pour connexion DirectQuery PostgreSQL / SQLite.

### üõ°Ô∏è S√©curit√© & Robustesse
| Aspect | Impl√©mentation |
| --- | --- |
| **Validation** | Pydantic strict sur tous les payloads API. |
| **Authentification** | Header X-API-KEY obligatoire pour `/predict`. |
| **R√©silience** | Fallback bootstrap si PostgreSQL indisponible. |
| **Tra√ßabilit√©** | Logs rotatifs (Loguru), m√©triques Prometheus. |

---

## üöÄ D√âMARRAGE RAPIDE

### Pr√©requis
* Python (v3.12+)
* pip

### Installation Express (3 commandes)
```powershell
cd "c:\Users\pc\Desktop\projet CAMRAIL"
pip install pandas numpy scikit-learn flask streamlit loguru pydantic joblib pyyaml python-dotenv
# Puis CIDP : Terminal A ‚Üí bootstrap + api ; Terminal B ‚Üí streamlit run dashboard/app.py
```

### Lancement D√©veloppeur (Mode Local ‚Äî Recommand√© pour d√©mo)

> üí° Utilisez le Python de **pyenv** si `python` ou `pip` ne sont pas configur√©s correctement.

```powershell
# 1. Installer les d√©pendances CIDP (pyenv recommand√©)
cd "c:\Users\pc\Desktop\projet CAMRAIL\Camrail-Industrial-Data-Platform"
& "$env:USERPROFILE\.pyenv\pyenv-win\versions\3.12.10\python.exe" -m pip install -r requirements.txt

# 2. Bootstrap + API ‚Äî Terminal 1
$env:PYTHONPATH = (Get-Location).Path
& "$env:USERPROFILE\.pyenv\pyenv-win\versions\3.12.10\python.exe" bootstrap_local.py
& "$env:USERPROFILE\.pyenv\pyenv-win\versions\3.12.10\python.exe" api/api.py

# 3. Dashboard Streamlit ‚Äî Terminal 2
cd "c:\Users\pc\Desktop\projet CAMRAIL\Camrail-Industrial-Data-Platform"
& "$env:USERPROFILE\.pyenv\pyenv-win\versions\3.12.10\python.exe" -m streamlit run dashboard/app.py
```

**Ordre requis :** Bootstrap + API en premier ; le Dashboard interroge l'API sur le port 5000 (sinon ReadTimeout).

### Acc√®s Imm√©diat
* **Dashboard :** http://localhost:8501  
* **API Backend :** http://127.0.0.1:5000  

---

## üìñ INSTALLATION COMPL√àTE

### Data Pipeline Automation (DPA)
```powershell
cd Data-Pipeline-Automation\src
python main_pipeline.py
```
**R√©sultat :** `database/supply_chain_dwh.sqlite` + `reports/rapport_supply_chain.xlsx`. Voir `exemples_excel_access/` pour Excel/Access.

### Predictive Maintenance Dashboard (PM-D)
```powershell
cd Predictive-Maintenance-Dashboard\src
python data_generator.py
python data_processing.py
python model_training.py
```
**R√©sultat :** `models/rf_failure_predict.joblib`

### Camrail Industrial Data Platform (CIDP)
```powershell
cd Camrail-Industrial-Data-Platform
$env:PYTHONPATH = (Get-Location).Path
python bootstrap_local.py
python api/api.py
# Terminal 2 :
streamlit run dashboard/app.py
```

Voir **[DEMARRAGE_RAPIDE.md](DEMARRAGE_RAPIDE.md)** pour les d√©tails.

---

## üìñ GUIDE D'UTILISATION

### Sc√©nario de Pilotage
1. **Connexion :** Lancez l'API puis le Dashboard Streamlit.
2. **Supervision :** Observez les sliders. Valeurs nominales (D√©bit 500, Pression 5, Vibrations 2, Temp√©rature 45) ‚Üí "OP√âRATION NOMINALE".
3. **Anticipation :** Augmentez Vibrations (7+) et Temp√©rature (85+) ‚Üí "DANGER D√âTECT√â".
4. **Action :** Exportez les donn√©es DWH (Excel automatique dans `reports/`) ou connectez Power BI (voir `POWER_BI_SPECS.md`).

### Captures d'√âcran
| DPA | CIDP | PM-D |
| --- | --- | --- |
| [Pipeline](docs/screenshots/05_dpa_pipeline_execution.png) ‚Ä¢ [DWH](docs/screenshots/06_dpa_sqlite_dwh.png) | [Vue](docs/screenshots/01_cidp_dashboard_vue_generale.png) ‚Ä¢ [Alerte](docs/screenshots/02_cidp_dashboard_alerte_danger.png) ‚Ä¢ [Timeout](docs/screenshots/09_cidp_dashboard_error_timeout.png) | [G√©n√©ration](docs/screenshots/07_pmd_generation_donnees.png) ‚Ä¢ [Training](docs/screenshots/08_pmd_model_training.png) |

---

## üì° API DOCUMENTATION

### Endpoints Disponibles

**1. Sant√© du Syst√®me**
```
GET /health
```
V√©rifie que l'API Flask est op√©rationnelle.

**2. Pr√©diction IA**
```
POST /predict
Headers: X-API-KEY: entreprise_secret_key_2026
Body: { "loco_id": "LOCO_001", "flow_rate": 500, "pressure": 5.0, "vibration": 2.0, "temperature": 45.0 }
```
Retourne `critical_risk` (0/1) et `risk_probability`.

**3. M√©triques Prometheus**
```
GET /metrics
```
Exposition des m√©triques SRE pour Grafana.

---

## ‚ú® QUALIT√â & BEST PRACTICES

### Standards de Code
* **Modularit√© :** Couches ETL, ML, API et Dashboard isol√©es.
* **Typage :** Dataframes Pandas typ√©s, validation Pydantic.
* **Error Handling :** Blocs try/except, messages d'erreur explicites.
* **Tests :** Pytest (`tests/test_api.py`) ‚Äî health, unauthorized, schema validation.

### M√©triques d'Excellence
‚úÖ **Couverture fonctionnelle :** ETL, ML, API, Dashboard end-to-end.
‚úÖ **Performance :** Temps de r√©ponse API < 200 ms.
‚úÖ **Disponibilit√© :** Mode bootstrap local sans d√©pendance Cloud.

---

## üó∫Ô∏è ROADMAP & √âVOLUTIONS

**Version Actuelle : 3.0.0 Enterprise ‚úÖ**
* Architecture E2E (DPA, CIDP, PM-D).
* Mode bootstrap local.
* Dashboard Streamlit avec X-API-KEY.
* Documentation DCE, PCR, Power BI Specs.

**Version 3.1.0 (Prochaine Release) üöß**
* Dockerisation : Conteneurs pour API, Dashboard, Kafka.
* Terraform : Provisionnement Azure complet.

**Version 4.0.0 (Vision Long Terme) üîÆ**
* Digital Twin : Jumeau num√©rique du parc locomotives.
* IoT : Connexion capteurs MQTT temps r√©el.
* Cloud Native : D√©ploiement AKS, Event Hubs.

---

## ü§ù CONTRIBUTION
Les contributions sont les bienvenues pour faire √©voluer ce d√©monstrateur vers une solution industrielle.

1. Forker.
2. Cr√©er une branche `feature/NomFeature`.
3. Proposer une Pull Request avec description m√©tier.

---

## üìÑ LICENCE
Ce projet est d√©velopp√© dans un cadre acad√©mique et professionnel. Droits r√©serv√©s.

---

## üë®‚Äçüíª AUTEUR

**KAMENI TCHOUATCHEU GAETAN BRUNEL**  
Ing√©nieur Logiciel & Data Scientist en devenir | √âtudiant ESIEA  

üìß Email : gaetanbrunel.kamenitchouatcheu@et.esiea.fr  
üêô GitHub : @Lkb-2905  

üôè **REMERCIEMENTS**
* **Bollor√© Logistics & Camrail :** Pour l'inspiration des cas d'usage logistiques industriels.
* **ESIEA :** Pour l'excellence de la formation ing√©nieur.

‚≠ê Si ce projet vous semble pertinent pour la Supply Chain de demain, laissez une √©toile !  
Fait avec ‚ù§Ô∏è, Python et Scikit-Learn.

¬© 2026 Kameni Tchouatcheu Gaetan Brunel ‚Äî Tous droits r√©serv√©s
