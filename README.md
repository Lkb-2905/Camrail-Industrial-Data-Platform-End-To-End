ğŸŒ DOSSIER DE CONFIGURATION D'EXPLOITATION (DCE)
# âš¡ CAMRAIL : ChaÃ®ne Logistique Ferroviaire & Maintenance PrÃ©dictive
![Python](https://img.shields.io/badge/Python-3.12+-green) ![Flask](https://img.shields.io/badge/Flask-API_REST-blue) ![Streamlit](https://img.shields.io/badge/Streamlit-Dashboard-orange) ![Data_Science](https://img.shields.io/badge/Data_Science-Random_Forest-red) ![Kafka](https://img.shields.io/badge/Kafka-Streaming-purple)

**Version:** 3.0.0 Enterprise | **Date:** FÃ©vrier 2026  
**Auteur:** KAMENI TCHOUATCHEU GAETAN BRUNEL  
**Contact:** gaetanbrunel.kamenitchouatcheu@et.esiea.fr  

ğŸš€ [DÃ©marrage Rapide](#-dÃ©marrage-rapide) â€¢ ğŸ“š [Documentation](#-guide-dutilisation) â€¢ ğŸ¯ [FonctionnalitÃ©s](#-fonctionnalitÃ©s-clÃ©s) â€¢ ğŸ”§ [Installation](#-installation-complÃ¨te)

---

## ğŸ“‹ TABLE DES MATIÃˆRES
1. [Vue d'ensemble du projet](#-vue-densemble-du-projet)
2. [Architecture Technique](#ï¸-architecture-technique)
3. [Stack Technologique](#ï¸-stack-technologique)
4. [FonctionnalitÃ©s ClÃ©s](#-fonctionnalitÃ©s-clÃ©s)
5. [DÃ©marrage Rapide](#-dÃ©marrage-rapide)
6. [Installation ComplÃ¨te](#-installation-complÃ¨te)
7. [Guide d'Utilisation](#-guide-dutilisation)
8. [API Documentation](#-api-documentation)
9. [QualitÃ© & Best Practices](#-qualitÃ©--best-practices)
10. [Roadmap & Ã‰volutions](#ï¸-roadmap--Ã©volutions)

---

## ğŸ¯ VUE D'ENSEMBLE DU PROJET

### Contexte & Objectifs
Ce projet dÃ©montre la mise en Å“uvre d'une architecture orientÃ©e **Data-Driven** pour le pilotage logistique ferroviaire (Camrail / BollorÃ© Logistics). Il rÃ©pond aux exigences de la Supply Chain moderne en combinant ETL, maintenance prÃ©dictive par l'IA et supervision temps rÃ©el.

Il illustre les compÃ©tences suivantes :

âœ… **Architecture DÃ©couplÃ©e :** SÃ©paration stricte ETL (Pandas) / API ML (Flask) / Dashboard (Streamlit).
âœ… **Data Science IntÃ©grÃ©e :** Moteur prÃ©dictif Scikit-Learn (Random Forest) pour la maintenance prÃ©dictive des locomotives.
âœ… **API RESTful :** Endpoints robustes avec validation Pydantic et authentification X-API-KEY.
âœ… **UX Moderne :** Interface de pilotage rÃ©active (Streamlit) avec sliders et feedback temps rÃ©el.
âœ… **Industrialisation :** Plan de ContinuitÃ© (PCR), documentation DCE, spÃ©cifications Power BI.
âœ… **Excel / Access :** IntÃ©gration bureautique â€” import Excel (source ERP), export rapports, lecture Access (voir `exemples_excel_access/`).
âœ… **Clean Code :** ModularitÃ©, tests automatisÃ©s (Pytest), compatibilitÃ© Pydantic v1/v2.

### Pourquoi ce projet ?
| Aspect | DÃ©monstration |
| --- | --- |
| **ScalabilitÃ©** | Architecture prÃªte pour Kafka, PostgreSQL et Kubernetes (AKS). |
| **MaintenabilitÃ©** | Code modulaire avec sÃ©paration ETL / ML / API / Dashboard. |
| **Innovation** | Hybride unique entre pipeline ETL, Data Science et monitoring temps rÃ©el. |
| **SÃ©curitÃ©** | X-API-KEY, validation Pydantic, secrets injectables. |
| **Performance** | ModÃ¨le ML sÃ©rialisÃ© (Joblib), chargement asynchrone, mode bootstrap local. |

---

## ğŸ—ï¸ ARCHITECTURE TECHNIQUE

### Diagramme de Flux
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Pipeline  â”‚     â”‚     CIDP     â”‚     â”‚       PM-D      â”‚
â”‚   Automation    â”‚     â”‚  (API + UI)  â”‚     â”‚ (Maintenance    â”‚
â”‚     (DPA)       â”‚     â”‚              â”‚     â”‚  PrÃ©dictive)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚                       â”‚
         â–¼                     â–¼                       â–¼
   supply_chain_dwh     models/latest.pkl        rf_failure_predict
   (SQLite)             API Flask:5000          .joblib
         â”‚                     â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    Streamlit Dashboard :8501
```

### Flux de DonnÃ©es DÃ©taillÃ©
1. **Extraction (DPA) :** DonnÃ©es API JSON et ERP CSV â†’ transformation Pandas â†’ chargement SQLite.
2. **PrÃ©diction (CIDP) :** Bootstrap ou PostgreSQL â†’ entraÃ®nement Random Forest â†’ `models/latest.pkl`.
3. **Supervision :** Dashboard Streamlit appelle l'API `/predict` avec tÃ©lÃ©mÃ©trie simulÃ©e (sliders).
4. **Maintenance (PM-D) :** GÃ©nÃ©ration tÃ©lÃ©mÃ©trie â†’ feature engineering â†’ entraÃ®nement modÃ¨le â†’ sÃ©rialisation Joblib.

---

## ğŸ› ï¸ STACK TECHNOLOGIQUE

### Technologies Core
| Composant | Technologie | Version | Justification Technique |
| --- | --- | --- | --- |
| **Langage** | Python | 3.12+ | Standard Data Science, ETL, ML. |
| **API** | Flask | 3.x | Endpoints REST, intÃ©gration Prometheus. |
| **Dashboard** | Streamlit | Latest | Interface rÃ©active, dÃ©mo temps rÃ©el. |
| **Data AI** | Scikit-Learn | Latest | Random Forest pour maintenance prÃ©dictive. |
| **ETL** | Pandas | Latest | Manipulation vectorielle, jointures, agrÃ©gations. |
| **Base** | SQLite / PostgreSQL | 3+ / 15+ | DWH lÃ©ger (local) ou Cloud. |

### BibliothÃ¨ques ComplÃ©mentaires
* **Pydantic :** Validation des payloads API (compatibilitÃ© v1/v2).
* **Loguru :** Logging structurÃ© avec rotation (10 MB / 30 jours).
* **Joblib :** SÃ©rialisation rapide des modÃ¨les ML.
* **Prometheus_client :** MÃ©triques SRE pour orchestrateurs.

---

## ğŸ¯ FONCTIONNALITÃ‰S CLÃ‰S

### ğŸš€ FonctionnalitÃ©s Principales

**Supervision Temps RÃ©el (CIDP)**
* Suivi des KPIs : DÃ©bit d'huile, Pression, Vibrations, TempÃ©rature.
* Dashboard Streamlit "Camrail Live Monitor" avec test manuel API.
* Affichage "OPÃ‰RATION NOMINALE" ou "DANGER DÃ‰TECTÃ‰" selon les prÃ©dictions.

**Intelligence Artificielle PrÃ©dictive**
* ModÃ¨le Random Forest pour dÃ©tecter les risques de panne imminente.
* Mode bootstrap local (entraÃ®nement depuis CSV sans PostgreSQL/Kafka).
* ProbabilitÃ© de risque et score binaire exposÃ©s via l'API.

**Gestion des Risques**
* DÃ©tection automatique des signatures mÃ©triques alarmantes.
* Alertes visuelles (banniÃ¨re rouge) et taux de fiabilitÃ© machine.

**Reporting & DWH**
* Pipeline ETL (DPA) : `fact_transactions`, `aggr_daily_site_stats`.
* **Export Excel** automatique vers `reports/rapport_supply_chain.xlsx` (multi-feuilles).
* **Excel / Access :** Lecture Excel comme source, export pour import Access. Exemples dans `exemples_excel_access/`.
* SpÃ©cifications Power BI pour connexion DirectQuery PostgreSQL / SQLite.

### ğŸ›¡ï¸ SÃ©curitÃ© & Robustesse
| Aspect | ImplÃ©mentation |
| --- | --- |
| **Validation** | Pydantic strict sur tous les payloads API. |
| **Authentification** | Header X-API-KEY obligatoire pour `/predict`. |
| **RÃ©silience** | Fallback bootstrap si PostgreSQL indisponible. |
| **TraÃ§abilitÃ©** | Logs rotatifs (Loguru), mÃ©triques Prometheus. |

---

## ğŸš€ DÃ‰MARRAGE RAPIDE

### PrÃ©requis
* Python (v3.12+)
* pip

### Installation Express (3 commandes)
```powershell
# 1. Cloner / naviguer vers le projet
cd "c:\Users\pc\Desktop\projet CAMRAIL"

# 2. Installer les dÃ©pendances
pip install pandas numpy scikit-learn flask streamlit loguru pydantic joblib pyyaml python-dotenv

# 3. Lancer la dÃ©mo CIDP (2 terminaux)
# Terminal A (API) :
cd Camrail-Industrial-Data-Platform
$env:PYTHONPATH = (Get-Location).Path
python bootstrap_local.py
python api/api.py
# Terminal B (Dashboard) :
streamlit run dashboard/app.py
```

### AccÃ¨s ImmÃ©diat
* **Dashboard :** http://localhost:8501  
* **API Backend :** http://127.0.0.1:5000  

---

## ğŸ“– INSTALLATION COMPLÃˆTE

### Data Pipeline Automation (DPA)
```powershell
cd Data-Pipeline-Automation\src
python main_pipeline.py
```
**RÃ©sultat :** `database/supply_chain_dwh.sqlite`

### Predictive Maintenance Dashboard (PM-D)
```powershell
cd Predictive-Maintenance-Dashboard\src
python data_generator.py
python data_processing.py
python model_training.py
```
**RÃ©sultat :** `models/rf_failure_predict.joblib`

### Camrail Industrial Data Platform (CIDP)
```powershell
cd Camrail-Industrial-Data-Platform
$env:PYTHONPATH = (Get-Location).Path
python bootstrap_local.py
python api/api.py
# Terminal 2 :
streamlit run dashboard/app.py
```

Voir **[DEMARRAGE_RAPIDE.md](DEMARRAGE_RAPIDE.md)** pour les dÃ©tails.

---

## ğŸ“– GUIDE D'UTILISATION

### ScÃ©nario de Pilotage
1. **Connexion :** Lancez l'API puis le Dashboard Streamlit.
2. **Supervision :** Observez les sliders. Valeurs nominales (DÃ©bit 500, Pression 5, Vibrations 2, TempÃ©rature 45) â†’ "OPÃ‰RATION NOMINALE".
3. **Anticipation :** Augmentez Vibrations (7+) et TempÃ©rature (85+) â†’ "DANGER DÃ‰TECTÃ‰".
4. **Action :** Exportez les donnÃ©es DWH ou connectez Power BI (voir `POWER_BI_SPECS.md`).

### Captures d'Ã‰cran
| Vue Globale | Cas Alerte | DÃ©pannage |
| --- | --- | --- |
| [01_vue_generale](docs/screenshots/01_cidp_dashboard_vue_generale.png) | [02_alerte](docs/screenshots/02_cidp_dashboard_alerte_danger.png) | [09_timeout](docs/screenshots/09_cidp_dashboard_error_timeout.png) |

---

## ğŸ“¡ API DOCUMENTATION

### Endpoints Disponibles

**1. SantÃ© du SystÃ¨me**
```
GET /health
```
VÃ©rifie que l'API Flask est opÃ©rationnelle.

**2. PrÃ©diction IA**
```
POST /predict
Headers: X-API-KEY: entreprise_secret_key_2026
Body: { "loco_id": "LOCO_001", "flow_rate": 500, "pressure": 5.0, "vibration": 2.0, "temperature": 45.0 }
```
Retourne `critical_risk` (0/1) et `risk_probability`.

**3. MÃ©triques Prometheus**
```
GET /metrics
```
Exposition des mÃ©triques SRE pour Grafana.

---

## âœ¨ QUALITÃ‰ & BEST PRACTICES

### Standards de Code
* **ModularitÃ© :** Couches ETL, ML, API et Dashboard isolÃ©es.
* **Typage :** Dataframes Pandas typÃ©s, validation Pydantic.
* **Error Handling :** Blocs try/except, messages d'erreur explicites.
* **Tests :** Pytest (`tests/test_api.py`) â€” health, unauthorized, schema validation.

### MÃ©triques d'Excellence
âœ… **Couverture fonctionnelle :** ETL, ML, API, Dashboard end-to-end.
âœ… **Performance :** Temps de rÃ©ponse API < 200 ms.
âœ… **DisponibilitÃ© :** Mode bootstrap local sans dÃ©pendance Cloud.

---

## ğŸ—ºï¸ ROADMAP & Ã‰VOLUTIONS

**Version Actuelle : 3.0.0 Enterprise âœ…**
* Architecture E2E (DPA, CIDP, PM-D).
* Mode bootstrap local.
* Dashboard Streamlit avec X-API-KEY.
* Documentation DCE, PCR, Power BI Specs.

**Version 3.1.0 (Prochaine Release) ğŸš§**
* Dockerisation : Conteneurs pour API, Dashboard, Kafka.
* Terraform : Provisionnement Azure complet.

**Version 4.0.0 (Vision Long Terme) ğŸ”®**
* Digital Twin : Jumeau numÃ©rique du parc locomotives.
* IoT : Connexion capteurs MQTT temps rÃ©el.
* Cloud Native : DÃ©ploiement AKS, Event Hubs.

---

## ğŸ¤ CONTRIBUTION
Les contributions sont les bienvenues pour faire Ã©voluer ce dÃ©monstrateur vers une solution industrielle.

1. Forker.
2. CrÃ©er une branche `feature/NomFeature`.
3. Proposer une Pull Request avec description mÃ©tier.

---

## ğŸ“„ LICENCE
Ce projet est dÃ©veloppÃ© dans un cadre acadÃ©mique et professionnel. Droits rÃ©servÃ©s.

---

## ğŸ‘¨â€ğŸ’» AUTEUR

**KAMENI TCHOUATCHEU GAETAN BRUNEL**  
IngÃ©nieur Logiciel & Data Scientist en devenir | Ã‰tudiant ESIEA  

ğŸ“§ Email : gaetanbrunel.kamenitchouatcheu@et.esiea.fr  
ğŸ™ GitHub : @Lkb-2905  

ğŸ™ **REMERCIEMENTS**
* **BollorÃ© Logistics & Camrail :** Pour l'inspiration des cas d'usage logistiques industriels.
* **ESIEA :** Pour l'excellence de la formation ingÃ©nieur.

â­ Si ce projet vous semble pertinent pour la Supply Chain de demain, laissez une Ã©toile !  
Fait avec â¤ï¸, Python et Scikit-Learn.

Â© 2026 Kameni Tchouatcheu Gaetan Brunel â€” Tous droits rÃ©servÃ©s
